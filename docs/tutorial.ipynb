{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMixer Tutorial\n",
    "\n",
    "This notebook contains code snippets demonstrating how `pymixer` package can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import required modules, classes, and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from pymixer.project import MidiTrackSpec, Project\n",
    "from pymixer.sound_makers import FluidsynthSoundMaker\n",
    "from sinethesizer.synth.core import Event\n",
    "from sinethesizer.effects.reverb import apply_room_reverb\n",
    "from sinethesizer.effects.stereo import apply_stereo_to_mono_conversion\n",
    "from sinethesizer.io.events_to_wav import write_timeline_to_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, put all input data to a single directory. In this tutorial, input data are three MIDI files constituting an introductory section of a fugue. This files are included in the repository as binary assets, so the below cell is valid even if it is left unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(), 'assets', 'tutorial_inputs')\n",
    "intermediate_dir = os.path.join(os.getcwd(), 'assets')\n",
    "output_dir = os.path.join(os.getcwd(), 'assets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is known, MIDI files do not contain any actual sounds; they contain only instructions how to produce it. Here, FluidSynth is used to generate audio output from MIDI files. Since FluidSynth is a soundfont player, a soundfont file is required. Pipe organ soundfonts look appropriate for our fugue sample. A soundfont based on the organ located at Pitea School of Music [is publicly available](https://stratmaninstruments.wordpress.com/swedish-organ-series) under Creative Commons Attribution-ShareAlike 2.5 license. Let us use it (update the path below if you saved the soundfont file to other place). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfont_path = os.path.join(\n",
    "    os.path.expanduser('~'), 'sound', 'soundfonts', 'j3.20_PiteaMHS_3.0', 'Pitea_3.0.sf2'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within `pymixer` domain, a track is a 2-channel audio with independent gain control and independent effects. In the next cell, it is defined how to make tracks from original MIDI files. Each track corresponds to its specification which is an instance of `MidiTrackSpec` class.\n",
    "\n",
    "This instance is responsible for two aspects:\n",
    "* how to produce sound from MIDI;\n",
    "* which input files to use.\n",
    "\n",
    "The latter thing is simple: a track uses contiguous sequence of input files and so it is enough to set the first one and the last one inclusively. In the below example, it is enough to put everywhere '01.mid' as a start and '03.mid' as an end. However, some of the ranges can be shorten, because fugue voices introduce one after the other.\n",
    "\n",
    "As for sound production, instance of either `FluidsynthSoundMaker` class or `SinethesizerSoundMaker` class is needed. Let us look closer at the former one, since only FluidSynth is used in this demo. The following things are configured below:\n",
    "* path to save an intermediate MIDI file that stores only relevant to the current track data (i.e., no other instruments and no preceeding or following events);\n",
    "* path to the soundfont;\n",
    "* dictionary that says which instruments to keep and which programs to use for playing them; for example, the first track includes only the instrument named '1' in the MIDI files and this instrument is mapped to program 15 (\"Gedackt 8'\" in the Pitea soundfont), whereas the second track includes exactly the same instrument, but now played with program 18 (\"Principal 4'\"); having two tracks with the same notes but different programs allows independent processing of this programs;\n",
    "* flags whether to use some built-in FluidSynth effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_specs = [\n",
    "    MidiTrackSpec(\n",
    "        FluidsynthSoundMaker(\n",
    "            f\"{intermediate_dir}/track_1.mid\",\n",
    "            soundfont_path,\n",
    "            {'1': 15},\n",
    "            fluidsynth_chorus=True\n",
    "        ),\n",
    "        '02.mid',\n",
    "        '03.mid'\n",
    "    ),\n",
    "    MidiTrackSpec(\n",
    "        FluidsynthSoundMaker(\n",
    "            f\"{intermediate_dir}/track_2.mid\",\n",
    "            soundfont_path,\n",
    "            {'1': 18},\n",
    "            fluidsynth_chorus=True\n",
    "        ),\n",
    "        '02.mid',\n",
    "        '03.mid'\n",
    "    ),\n",
    "    MidiTrackSpec(\n",
    "        FluidsynthSoundMaker(\n",
    "            f\"{intermediate_dir}/track_3.mid\",\n",
    "            soundfont_path,\n",
    "            {'2': 5},\n",
    "            fluidsynth_chorus=True\n",
    "        ),\n",
    "        '01.mid',\n",
    "        '03.mid'\n",
    "    ),\n",
    "    MidiTrackSpec(\n",
    "        FluidsynthSoundMaker(\n",
    "            f\"{intermediate_dir}/track_4.mid\",\n",
    "            soundfont_path,\n",
    "            {'2': 6},\n",
    "            fluidsynth_chorus=True\n",
    "        ),\n",
    "        '01.mid',\n",
    "        '03.mid'\n",
    "    ),\n",
    "    MidiTrackSpec(\n",
    "        FluidsynthSoundMaker(\n",
    "            f\"{intermediate_dir}/track_5.mid\",\n",
    "            soundfont_path,\n",
    "            {'3': 23},\n",
    "            fluidsynth_chorus=True\n",
    "        ),\n",
    "        '03.mid',\n",
    "        '03.mid'\n",
    "    ),\n",
    "    MidiTrackSpec(\n",
    "        FluidsynthSoundMaker(\n",
    "            f\"{intermediate_dir}/track_6.mid\",\n",
    "            soundfont_path,\n",
    "            {'3': 25},\n",
    "            fluidsynth_chorus=True\n",
    "        ),\n",
    "        '03.mid',\n",
    "        '03.mid'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then tracks configuration must be passed to a mixing project represented by `Project` class.\n",
    "\n",
    "Optional argument `offsets` sets interlocation of each pair of adjacent MIDI inputs. Positive values stand for pauses (caesuras, in musical jargon) and negative values stand for overlappings: the *(i+1)*-th file starts before the *i*-th file ends.\n",
    "\n",
    "Please note that all opening and trailing silences from MIDI files are ignored by `pymixer`. Use `offsets` argument to separate parts with pauses. As for opening and trailing silences for the output as a whole, use eponymous arguments of `mix` method (see further)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Project(\n",
    "    input_dir,\n",
    "    tracks_specs,\n",
    "    offsets=[0.0, 0.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time, all MIDI inputs are converted to audio stored in-memory as `numpy` arrays. Now, the mixing itself starts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Applying effects to tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, every function that takes `numpy` array as input and returns `numpy` array as output can be used for applying effects. In this tutorial, `sinethesizer` effects are chosen as an example. It is supposed that our goal is to erase original panning (if any) and then introduce a new panning with a room reverb so that all tracks based on the instrument named '1' are located to the left, all tracks based on the instrument named '2' are located to the right and all tracks based on the instrument named '3' are centered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `sinethesizer` event is needed for all `sinethesizer` effects. For some effects, this event affects the output, but this is not the case for reverb and stereo-to-mono conversion. So let us create a placeholder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_event = Event(\n",
    "    instrument='does_not_matter',\n",
    "    start_time=0,\n",
    "    duration=1,\n",
    "    frequency=1,\n",
    "    velocity=1,\n",
    "    effects=\"\",\n",
    "    frame_rate=project.frame_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell configures three reverb presets with reflections of sound waves within a room being simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb_params_by_name = {\n",
    "    'left': {\n",
    "        \"room_length\": 65, \"room_width\": 25, \"room_height\": 15,\n",
    "        \"reflection_decay_factor\": 0.7, \"sound_speed\": 343,\n",
    "        \"listener_x\": 45, \"listener_y\": 12.5, \"listener_z\": 1.7,\n",
    "        \"listener_direction_x\": 1, \"listener_direction_y\": 0,\n",
    "        \"sound_source_x\": 57.124355652982146, \"sound_source_y\": 19.5, \"sound_source_z\": 4,\n",
    "        \"sound_source_direction_x\": -0.8660254037844387, \"sound_source_direction_y\": -0.49999999999999994, \"sound_source_direction_z\": 0,\n",
    "        \"angle\": 1.5707963267948966, \"n_reflections\": 30\n",
    "    },\n",
    "    'center': {\n",
    "        \"room_length\": 65, \"room_width\": 25, \"room_height\": 15,\n",
    "        \"reflection_decay_factor\": 0.7, \"sound_speed\": 343,\n",
    "        \"listener_x\": 45, \"listener_y\": 12.5, \"listener_z\": 1.7,\n",
    "        \"listener_direction_x\": 1, \"listener_direction_y\": 0,\n",
    "        \"sound_source_x\": 59.0, \"sound_source_y\": 12.5, \"sound_source_z\": 4,\n",
    "        \"sound_source_direction_x\": -1.0, \"sound_source_direction_y\": -0.0, \"sound_source_direction_z\": 0,\n",
    "        \"angle\": 1.5707963267948966, \"n_reflections\": 30\n",
    "    },\n",
    "    'right': {\n",
    "        \"room_length\": 65, \"room_width\": 25, \"room_height\": 15,\n",
    "        \"reflection_decay_factor\": 0.7, \"sound_speed\": 343,\n",
    "        \"listener_x\": 45, \"listener_y\": 12.5, \"listener_z\": 1.7,\n",
    "        \"listener_direction_x\": 1, \"listener_direction_y\": 0,\n",
    "        \"sound_source_x\": 57.124355652982146, \"sound_source_y\": 5.500000000000001, \"sound_source_z\": 4,\n",
    "        \"sound_source_direction_x\": -0.8660254037844387, \"sound_source_direction_y\": 0.49999999999999994, \"sound_source_direction_z\": 0,\n",
    "        \"angle\": 1.5707963267948966, \"n_reflections\": 30\n",
    "    },\n",
    "}\n",
    "instrument_name_to_reverb_params = {\n",
    "    '1': reverb_params_by_name['left'],\n",
    "    '2': reverb_params_by_name['right'],\n",
    "    '3': reverb_params_by_name['center'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the effects. Initial panning is erased with stereo-to-mono conversion and then room reverb creates new panning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_names = [\n",
    "    k\n",
    "    for track_spec in tracks_specs\n",
    "    for k in track_spec.sound_maker.instrument_name_to_program.keys()\n",
    "]\n",
    "for index, instrument_name in enumerate(instrument_names):\n",
    "    project.tracks[index].timeline = apply_stereo_to_mono_conversion(\n",
    "        project.tracks[index].timeline,\n",
    "        dummy_event\n",
    "    )\n",
    "    project.tracks[index].timeline = apply_room_reverb(\n",
    "        project.tracks[index].timeline,\n",
    "        dummy_event,\n",
    "        **instrument_name_to_reverb_params[instrument_name]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Evaluation of the mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, track gains can be changed easily until mixed sound is good enough. Just execute the cell iteratively as many times as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = [1.0, 1.0, 1.0, 1.0, 1.2, 1.2]\n",
    "opening_silence = 0.5\n",
    "trailing_silence = 0.5\n",
    "\n",
    "timeline = project.mix(gains, opening_silence, trailing_silence)\n",
    "timeline /= np.max(np.abs(timeline))\n",
    "IPython.display.Audio(timeline, rate=project.frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As proverb says, it is better to see something once than to hear about it multiple times. Let us inspect the mix visually as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_track_indices = []\n",
    "for _, group in itertools.groupby(sorted(enumerate(instrument_names), key=lambda x: x[1]), key=lambda x: x[1]):\n",
    "    grouped_track_indices.append([x[0] for x in group])\n",
    "timelines = project.mix(gains, opening_silence, trailing_silence, grouped_track_indices)\n",
    "\n",
    "unique_instrument_names = set(instrument_names)\n",
    "fig = plt.figure(figsize=(15, 3 * len(unique_instrument_names)))\n",
    "first_ax = None\n",
    "for i, instrument_name in enumerate(sorted(unique_instrument_names)):\n",
    "    ax_location = len(unique_instrument_names) * 100 + 11 + i\n",
    "    if first_ax is None:\n",
    "        ax = fig.add_subplot(ax_location)\n",
    "        first_ax = ax\n",
    "    else:\n",
    "        ax = fig.add_subplot(ax_location, sharey=first_ax)\n",
    "    mono_timeline = np.sum(timelines[(2 * i):(2 * i + 1), :], axis=0) / 2  # Average over channels is visualized.\n",
    "    ax.plot(mono_timeline)\n",
    "    for track in project.tracks:\n",
    "        ax.axvline(project.frame_rate * (track.start_time + opening_silence), c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Saving WAV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_timeline_to_wav(f'{output_dir}/result.wav', timeline, project.frame_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
